{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries & Data\n",
    "\n",
    "Apprentice Chef Analysis - Classification Modelling\n",
    "\n",
    "Vi Nguyen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# importing all libraries\n",
    "import pandas as pd                                   # data science essentials\n",
    "import matplotlib.pyplot as plt                       # data visualization\n",
    "import seaborn as sns                                 # enhanced data visualization\n",
    "import numpy as np                                    # numpy for math\n",
    "from sklearn.model_selection import train_test_split  # train-test split\n",
    "from sklearn.linear_model import LogisticRegression   # logistic regression\n",
    "import statsmodels.formula.api as smf                 # logistic regression\n",
    "from sklearn.metrics import confusion_matrix          # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score             # auc score\n",
    "from sklearn.neighbors import KNeighborsClassifier    # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor     # KNN for regression\n",
    "from sklearn.preprocessing import StandardScaler      # standard scaler\n",
    "\n",
    "# CART model packages\n",
    "from sklearn.tree import DecisionTreeClassifier       # classification trees\n",
    "from sklearn.tree import export_graphviz              # exports graphics\n",
    "from six import StringIO                              # saves objects in memory\n",
    "from IPython.display import Image                     # displays on frontend\n",
    "import pydotplus                                      # interprets dot objects\n",
    "\n",
    "#Packages for Classification Tree Modelling\n",
    "from sklearn.model_selection import RandomizedSearchCV  # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer                 # customizable scorer\n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm\n",
    "\n",
    "# setting pd print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "# specify path and file name\n",
    "file = 'Apprentice_Chef_Dataset.xlsx'\n",
    "\n",
    "\n",
    "# reading the file\n",
    "chef = pd.read_excel(io=file)\n",
    "\n",
    "# #running the file\n",
    "# chef.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# text_split_feature UDF\n",
    "#########################\n",
    "def text_split_feature(col, df, sep=' ', new_col_name = 'NUM_OF_NAMES'):\n",
    "    \"\"\"\n",
    "Splits values in a string Series (as part of a DataFrame) and sums the number\n",
    "of resulting items. Automatically appends summed column to original DataFrame.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "col          : column to split\n",
    "df           : DataFrame where column is located\n",
    "sep          : string sequence to split by, default ' '\n",
    "new_col_name : name of new column after summing split, default\n",
    "               'number_of_names'\n",
    "\"\"\"\n",
    "    \n",
    "    df[new_col_name] = 0\n",
    "    \n",
    "    \n",
    "    for index, val in df.iterrows():\n",
    "        df.loc[index, new_col_name] = len(df.loc[index, col].split(sep = ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# optimal_neighbors UDF\n",
    "########################################\n",
    "def optimal_neighbors(x_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.25,\n",
    "                      seed=219,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "x_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "standardize   : whether or not to standardize the X data, default True\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 219\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "show_viz      : display or surpress k-neigbors visualization, default True\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing X_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(x_data)\n",
    "        x_scaled           = scaler.transform(x_data)\n",
    "        x_scaled_df        = pd.DataFrame(x_scaled)\n",
    "        x_data             = x_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(x_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(x_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization\n",
    "    if show_viz == True:\n",
    "        # plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "###Cleaning and Splitting Emails into Necessary Domains\n",
    "\n",
    "# STEP 1: splitting emails at the @ sign\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping each email address\n",
    "for index, col in chef.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "    split_email = chef.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "\n",
    "# convert to df \n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "# STEP 2:CONCATENATING DOMAINS AS A NEW COLUMN IN CHEF DF\n",
    "\n",
    "# safety measure in case of multiple concatenations\n",
    "chef = pd.read_excel(file)\n",
    "\n",
    "\n",
    "# renaming column to concatenate\n",
    "email_df.columns = ['0' , 'EMAIL_DOMAINS']\n",
    "\n",
    "\n",
    "# concatenating email domains to chef\n",
    "#adds the column to the dataset\n",
    "chef = pd.concat([chef, email_df['EMAIL_DOMAINS']],\n",
    "                   axis = 1)\n",
    "\n",
    "# STEP 3: splitting emails at the '.'\n",
    "\n",
    "# dot holder list (emails with no dots)\n",
    "dotholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in chef.iterrows():\n",
    "    \n",
    "    # splitting email domain at '.'\n",
    "    dot_email = chef.loc[index, 'EMAIL_DOMAINS'].split(sep = '.')\n",
    "    \n",
    "    # appending dotholder_lst with the results\n",
    "    dotholder_lst.append(dot_email)\n",
    "    \n",
    "\n",
    "# converting cleanemail_df into a DataFrame \n",
    "cleanemail_df = pd.DataFrame(dotholder_lst)\n",
    "\n",
    "# # displaying the results\n",
    "# cleanemail_df\n",
    "\n",
    "# STEP 4 :CONCATENATING CLEAN EMAIL DOMAINS AS A NEW COLUMN IN CHEF DF\n",
    "\n",
    "# safety measure in case of multiple concatenations\n",
    "chef = pd.read_excel(file)\n",
    "\n",
    "\n",
    "# renaming column to concatenate\n",
    "cleanemail_df.columns = ['CLEAN_MAIL' , '1']\n",
    "\n",
    "#add the column to the dataset\n",
    "chef = pd.concat([chef, cleanemail_df['CLEAN_MAIL']],\n",
    "                   axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# STEP 5: Aggregating personal and work emails\n",
    "\n",
    "# email domain types\n",
    "personal_email_domains = ['gmail','protonmail','yahoo']\n",
    "\n",
    "work_email_domains  = ['amex','cocacola','jnj','merck',\n",
    "                       'mcdonalds','nike','apple','dupont','ibm',\n",
    "                       'ge','microsoft','chevron','travelers',\n",
    "                       'exxon','unitedhealth','boeing','caterpillar',\n",
    "                       'mmm','pg','verizon','walmart','disney',\n",
    "                       'pfizer','visa','jpmorgan','unitedtech',\n",
    "                       'cisco','goldmansacs','intel','homedepot']\n",
    "\n",
    "junk_email_domains = ['msn','aol','hotmail','live','me', 'passport']\n",
    "\n",
    "# placeholder list\n",
    "holder_lst = []\n",
    "\n",
    "# looping to group observations by domain type\n",
    "for domain in chef['CLEAN_MAIL']:\n",
    "    \n",
    "        if domain in personal_email_domains:\n",
    "            holder_lst.append('personal')\n",
    "            \n",
    "        elif domain in work_email_domains:\n",
    "            holder_lst.append('work')\n",
    "        \n",
    "        elif domain in junk_email_domains:\n",
    "            holder_lst.append('junk')\n",
    "            \n",
    "        else:\n",
    "            print('Unknown')\n",
    "\n",
    "\n",
    "# concatenating with original DataFrame\n",
    "chef['DOMAIN_GROUP'] = pd.Series(holder_lst)\n",
    "\n",
    "# # checking results\n",
    "# chef['DOMAIN_GROUP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Taking out personal and work emails into columns \n",
    "# one hot encoding domain groups\n",
    "ONE_HOT_DOMAIN = pd.get_dummies(chef['DOMAIN_GROUP'])\n",
    "\n",
    "# dropping categorical variables after they've been encoded\n",
    "chef = chef.drop('DOMAIN_GROUP', axis = 1)\n",
    "\n",
    "# joining codings together\n",
    "chef = chef.join([ONE_HOT_DOMAIN])\n",
    "\n",
    "# saving new columns\n",
    "new_columns = chef.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# calling text_split_feature to count names \n",
    "text_split_feature('NAME', chef, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#creating dummies for customers that were above the average\n",
    "#L=[50%]\n",
    "# dummy variables for vars with zeros.\n",
    "chef['abv_TOTAL_MEALS_ORDERED']        = 0\n",
    "chef['abv_UNIQUE_MEALS_PURCH']        = 0\n",
    "for index, value in chef.iterrows():\n",
    "    \n",
    "    #total meals\n",
    "    if chef.loc[index, 'TOTAL_MEALS_ORDERED'] > chef.loc[:,'TOTAL_MEALS_ORDERED'].median():\n",
    "        chef.loc[index, 'abv_TOTAL_MEALS_ORDERED'] = 1\n",
    "        \n",
    "    #uniqe meals\n",
    "    if chef.loc[index, 'UNIQUE_MEALS_PURCH'] > chef.loc[:,'UNIQUE_MEALS_PURCH'].median():\n",
    "        chef.loc[index, 'abv_UNIQUE_MEALS_PURCH'] = 1  \n",
    "        \n",
    "#printing out variables        \n",
    "# chef[['abv_TOTAL_MEALS_ORDERED','abv_UNIQUE_MEALS_PURCH']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# creating a column for avg price meal\n",
    "chef['AVG_PRICE_MEAL'] = chef['REVENUE']/chef['TOTAL_MEALS_ORDERED'].round(2)\n",
    "\n",
    "#types of users \n",
    "chef['med_rater']     = 0\n",
    "\n",
    "#itterating through the data to create user data\n",
    "for index, val in chef.iterrows():\n",
    "        \n",
    "    #median rating for the price of meal if effected\n",
    "    if chef.loc[index, 'MEDIAN_MEAL_RATING'] <= 3 and chef.loc[index, 'AVG_PRICE_MEAL'] > 34:\n",
    "        chef.loc[index, 'med_rater'] = 1  \n",
    "\n",
    "#checking variables just initiated \n",
    "# chef['med_rater'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving feature-rich Chef dataset in excel\n",
    "chef.to_excel('Chef_Ft_Classification.xlsx',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#dropping categorical variables/variables with strings\n",
    "\n",
    "# declaring x-variables\n",
    "chef_data = chef.drop(['CROSS_SELL_SUCCESS', 'NAME', 'EMAIL',\n",
    "                       'FIRST_NAME', 'FAMILY_NAME', 'CLEAN_MAIL'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#checking correlations of the dataset and engineered features \n",
    "chef_corr = chef.corr().round(2)\n",
    "\n",
    "# chef_corr['CROSS_SELL_SUCCESS'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# declaring explanatory variables\n",
    "chef_data = chef.drop(['CROSS_SELL_SUCCESS', 'NAME', 'EMAIL',\n",
    "                       'FIRST_NAME', 'FAMILY_NAME', 'CLEAN_MAIL'], axis = 1)\n",
    "\n",
    "# declaring response variable\n",
    "chef_target = chef.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "# train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            chef_data,\n",
    "            chef_target,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219,\n",
    "            stratify     = chef_target)\n",
    "\n",
    "\n",
    "# merging training data for statsmodels\n",
    "chef_train = pd.concat([x_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " REVENUE + \n",
      " TOTAL_MEALS_ORDERED + \n",
      " UNIQUE_MEALS_PURCH + \n",
      " CONTACTS_W_CUSTOMER_SERVICE + \n",
      " PRODUCT_CATEGORIES_VIEWED + \n",
      " AVG_TIME_PER_SITE_VISIT + \n",
      " MOBILE_NUMBER + \n",
      " CANCELLATIONS_BEFORE_NOON + \n",
      " CANCELLATIONS_AFTER_NOON + \n",
      " TASTES_AND_PREFERENCES + \n",
      " PC_LOGINS + \n",
      " MOBILE_LOGINS + \n",
      " WEEKLY_PLAN + \n",
      " EARLY_DELIVERIES + \n",
      " LATE_DELIVERIES + \n",
      " PACKAGE_LOCKER + \n",
      " REFRIGERATED_LOCKER + \n",
      " AVG_PREP_VID_TIME + \n",
      " LARGEST_ORDER_SIZE + \n",
      " MASTER_CLASSES_ATTENDED + \n",
      " MEDIAN_MEAL_RATING + \n",
      " AVG_CLICKS_PER_VISIT + \n",
      " TOTAL_PHOTOS_VIEWED + \n",
      " junk + \n",
      " personal + \n",
      " work + \n",
      " NUM_OF_NAMES + \n",
      " abv_TOTAL_MEALS_ORDERED + \n",
      " abv_UNIQUE_MEALS_PURCH + \n",
      " AVG_PRICE_MEAL + \n",
      " med_rater + \n"
     ]
    }
   ],
   "source": [
    "#adding a + to each variable\n",
    "#locked to not print\n",
    "#used to determine significant variables based on p-values below\n",
    "for val in chef_data:\n",
    "    print(f\" {val} + \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.540243\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>CROSS_SELL_SUCCESS</td> <th>  No. Observations:  </th>  <td>  1459</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>Logit</td>       <th>  Df Residuals:      </th>  <td>  1448</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>        <th>  Df Model:          </th>  <td>    10</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 16 Mar 2021</td>  <th>  Pseudo R-squ.:     </th>  <td>0.1397</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:09:50</td>      <th>  Log-Likelihood:    </th> <td> -788.22</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>        <th>  LL-Null:           </th> <td> -916.19</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>  LLR p-value:       </th> <td>3.032e-49</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                 <td>   -4.1156</td> <td>    0.674</td> <td>   -6.105</td> <td> 0.000</td> <td>   -5.437</td> <td>   -2.794</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MOBILE_NUMBER</th>             <td>    0.9029</td> <td>    0.177</td> <td>    5.101</td> <td> 0.000</td> <td>    0.556</td> <td>    1.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CANCELLATIONS_BEFORE_NOON</th> <td>    0.2804</td> <td>    0.046</td> <td>    6.033</td> <td> 0.000</td> <td>    0.189</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TASTES_AND_PREFERENCES</th>    <td>    0.4083</td> <td>    0.136</td> <td>    3.006</td> <td> 0.003</td> <td>    0.142</td> <td>    0.674</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_LOGINS</th>                 <td>    0.2317</td> <td>    0.107</td> <td>    2.159</td> <td> 0.031</td> <td>    0.021</td> <td>    0.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EARLY_DELIVERIES</th>          <td>    0.0571</td> <td>    0.028</td> <td>    2.065</td> <td> 0.039</td> <td>    0.003</td> <td>    0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REFRIGERATED_LOCKER</th>       <td>    0.5204</td> <td>    0.208</td> <td>    2.498</td> <td> 0.013</td> <td>    0.112</td> <td>    0.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>work</th>                      <td>    1.9067</td> <td>    0.172</td> <td>   11.093</td> <td> 0.000</td> <td>    1.570</td> <td>    2.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>personal</th>                  <td>    1.3214</td> <td>    0.158</td> <td>    8.387</td> <td> 0.000</td> <td>    1.013</td> <td>    1.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NUM_OF_NAMES</th>              <td>    0.5479</td> <td>    0.094</td> <td>    5.834</td> <td> 0.000</td> <td>    0.364</td> <td>    0.732</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>med_rater</th>                 <td>   -0.3765</td> <td>    0.124</td> <td>   -3.030</td> <td> 0.002</td> <td>   -0.620</td> <td>   -0.133</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:     CROSS_SELL_SUCCESS   No. Observations:                 1459\n",
       "Model:                          Logit   Df Residuals:                     1448\n",
       "Method:                           MLE   Df Model:                           10\n",
       "Date:                Tue, 16 Mar 2021   Pseudo R-squ.:                  0.1397\n",
       "Time:                        13:09:50   Log-Likelihood:                -788.22\n",
       "converged:                       True   LL-Null:                       -916.19\n",
       "Covariance Type:            nonrobust   LLR p-value:                 3.032e-49\n",
       "=============================================================================================\n",
       "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------\n",
       "Intercept                    -4.1156      0.674     -6.105      0.000      -5.437      -2.794\n",
       "MOBILE_NUMBER                 0.9029      0.177      5.101      0.000       0.556       1.250\n",
       "CANCELLATIONS_BEFORE_NOON     0.2804      0.046      6.033      0.000       0.189       0.371\n",
       "TASTES_AND_PREFERENCES        0.4083      0.136      3.006      0.003       0.142       0.674\n",
       "PC_LOGINS                     0.2317      0.107      2.159      0.031       0.021       0.442\n",
       "EARLY_DELIVERIES              0.0571      0.028      2.065      0.039       0.003       0.111\n",
       "REFRIGERATED_LOCKER           0.5204      0.208      2.498      0.013       0.112       0.929\n",
       "work                          1.9067      0.172     11.093      0.000       1.570       2.244\n",
       "personal                      1.3214      0.158      8.387      0.000       1.013       1.630\n",
       "NUM_OF_NAMES                  0.5479      0.094      5.834      0.000       0.364       0.732\n",
       "med_rater                    -0.3765      0.124     -3.030      0.002      -0.620      -0.133\n",
       "=============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##      LOG REGRESSION MODEL W/STATSMOD      ##\n",
    "###############################################\n",
    "\n",
    "#significant set 2\n",
    "# instantiating a logistic regression model object\n",
    "logistic_full = smf.logit(formula = \"\"\" CROSS_SELL_SUCCESS ~ \n",
    "                                         MOBILE_NUMBER + \n",
    "                                         CANCELLATIONS_BEFORE_NOON +  \n",
    "                                         TASTES_AND_PREFERENCES + \n",
    "                                         PC_LOGINS + \n",
    "                                         EARLY_DELIVERIES + \n",
    "                                         REFRIGERATED_LOCKER + \n",
    "                                         work + \n",
    "                                         personal + \n",
    "                                         NUM_OF_NAMES +\n",
    "                                         med_rater\"\"\",\n",
    "                                        data = chef_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_full = logistic_full.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.536436\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>CROSS_SELL_SUCCESS</td> <th>  No. Observations:  </th>  <td>  1459</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>Logit</td>       <th>  Df Residuals:      </th>  <td>  1444</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>        <th>  Df Model:          </th>  <td>    14</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 16 Mar 2021</td>  <th>  Pseudo R-squ.:     </th>  <td>0.1457</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:11:27</td>      <th>  Log-Likelihood:    </th> <td> -782.66</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>        <th>  LL-Null:           </th> <td> -916.19</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>  LLR p-value:       </th> <td>8.381e-49</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                   <td>   -3.3112</td> <td>    0.696</td> <td>   -4.759</td> <td> 0.000</td> <td>   -4.675</td> <td>   -1.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REVENUE</th>                     <td>-9.317e-05</td> <td> 6.91e-05</td> <td>   -1.349</td> <td> 0.177</td> <td>   -0.000</td> <td> 4.22e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CONTACTS_W_CUSTOMER_SERVICE</th> <td>    0.0701</td> <td>    0.028</td> <td>    2.486</td> <td> 0.013</td> <td>    0.015</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MOBILE_NUMBER</th>               <td>    0.9189</td> <td>    0.178</td> <td>    5.155</td> <td> 0.000</td> <td>    0.570</td> <td>    1.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CANCELLATIONS_BEFORE_NOON</th>   <td>    0.2785</td> <td>    0.047</td> <td>    5.951</td> <td> 0.000</td> <td>    0.187</td> <td>    0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TASTES_AND_PREFERENCES</th>      <td>    0.3975</td> <td>    0.137</td> <td>    2.910</td> <td> 0.004</td> <td>    0.130</td> <td>    0.665</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC_LOGINS</th>                   <td>    0.2392</td> <td>    0.108</td> <td>    2.217</td> <td> 0.027</td> <td>    0.028</td> <td>    0.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EARLY_DELIVERIES</th>            <td>    0.0572</td> <td>    0.028</td> <td>    2.064</td> <td> 0.039</td> <td>    0.003</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REFRIGERATED_LOCKER</th>         <td>    0.5291</td> <td>    0.210</td> <td>    2.522</td> <td> 0.012</td> <td>    0.118</td> <td>    0.940</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MASTER_CLASSES_ATTENDED</th>     <td>    0.2369</td> <td>    0.109</td> <td>    2.169</td> <td> 0.030</td> <td>    0.023</td> <td>    0.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>junk</th>                        <td>   -1.3536</td> <td>    0.160</td> <td>   -8.465</td> <td> 0.000</td> <td>   -1.667</td> <td>   -1.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>work</th>                        <td>    0.5922</td> <td>    0.145</td> <td>    4.081</td> <td> 0.000</td> <td>    0.308</td> <td>    0.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NUM_OF_NAMES</th>                <td>    0.5572</td> <td>    0.094</td> <td>    5.916</td> <td> 0.000</td> <td>    0.373</td> <td>    0.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>abv_TOTAL_MEALS_ORDERED</th>     <td>    0.0772</td> <td>    0.180</td> <td>    0.429</td> <td> 0.668</td> <td>   -0.275</td> <td>    0.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>med_rater</th>                   <td>   -0.3882</td> <td>    0.163</td> <td>   -2.378</td> <td> 0.017</td> <td>   -0.708</td> <td>   -0.068</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:     CROSS_SELL_SUCCESS   No. Observations:                 1459\n",
       "Model:                          Logit   Df Residuals:                     1444\n",
       "Method:                           MLE   Df Model:                           14\n",
       "Date:                Tue, 16 Mar 2021   Pseudo R-squ.:                  0.1457\n",
       "Time:                        13:11:27   Log-Likelihood:                -782.66\n",
       "converged:                       True   LL-Null:                       -916.19\n",
       "Covariance Type:            nonrobust   LLR p-value:                 8.381e-49\n",
       "===============================================================================================\n",
       "                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "Intercept                      -3.3112      0.696     -4.759      0.000      -4.675      -1.948\n",
       "REVENUE                     -9.317e-05   6.91e-05     -1.349      0.177      -0.000    4.22e-05\n",
       "CONTACTS_W_CUSTOMER_SERVICE     0.0701      0.028      2.486      0.013       0.015       0.125\n",
       "MOBILE_NUMBER                   0.9189      0.178      5.155      0.000       0.570       1.268\n",
       "CANCELLATIONS_BEFORE_NOON       0.2785      0.047      5.951      0.000       0.187       0.370\n",
       "TASTES_AND_PREFERENCES          0.3975      0.137      2.910      0.004       0.130       0.665\n",
       "PC_LOGINS                       0.2392      0.108      2.217      0.027       0.028       0.451\n",
       "EARLY_DELIVERIES                0.0572      0.028      2.064      0.039       0.003       0.112\n",
       "REFRIGERATED_LOCKER             0.5291      0.210      2.522      0.012       0.118       0.940\n",
       "MASTER_CLASSES_ATTENDED         0.2369      0.109      2.169      0.030       0.023       0.451\n",
       "junk                           -1.3536      0.160     -8.465      0.000      -1.667      -1.040\n",
       "work                            0.5922      0.145      4.081      0.000       0.308       0.877\n",
       "NUM_OF_NAMES                    0.5572      0.094      5.916      0.000       0.373       0.742\n",
       "abv_TOTAL_MEALS_ORDERED         0.0772      0.180      0.429      0.668      -0.275       0.430\n",
       "med_rater                      -0.3882      0.163     -2.378      0.017      -0.708      -0.068\n",
       "===============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  LOG REGRESSION MODEL W/STATSMOD & SET 3  ##\n",
    "###############################################\n",
    "\n",
    "#significant set 3\n",
    "# instantiating a logistic regression model object\n",
    "logistic_full = smf.logit(formula = \"\"\" CROSS_SELL_SUCCESS ~ \n",
    "                                         REVENUE +\n",
    "                                         CONTACTS_W_CUSTOMER_SERVICE +\n",
    "                                         MOBILE_NUMBER + \n",
    "                                         CANCELLATIONS_BEFORE_NOON +\n",
    "                                         TASTES_AND_PREFERENCES + \n",
    "                                         PC_LOGINS +\n",
    "                                         EARLY_DELIVERIES +\n",
    "                                         REFRIGERATED_LOCKER +\n",
    "                                         MASTER_CLASSES_ATTENDED +\n",
    "                                         junk + \n",
    "                                         work + \n",
    "                                         NUM_OF_NAMES + \n",
    "                                         abv_TOTAL_MEALS_ORDERED +\n",
    "                                         med_rater  \"\"\",\n",
    "                                        data = chef_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_full = logistic_full.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_full.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# creating a variable dictionary to store candidate models\n",
    "\n",
    "variable_dict = {\n",
    "\n",
    " # full model\n",
    " 'logit_full'   : ['REVENUE','TOTAL_MEALS_ORDERED','UNIQUE_MEALS_PURCH',\n",
    "                   'CONTACTS_W_CUSTOMER_SERVICE','PRODUCT_CATEGORIES_VIEWED',\n",
    "                   'AVG_TIME_PER_SITE_VISIT','MOBILE_NUMBER','CANCELLATIONS_BEFORE_NOON',\n",
    "                   'CANCELLATIONS_AFTER_NOON','TASTES_AND_PREFERENCES','PC_LOGINS',\n",
    "                   'MOBILE_LOGINS','WEEKLY_PLAN','EARLY_DELIVERIES','LATE_DELIVERIES',\n",
    "                   'PACKAGE_LOCKER','REFRIGERATED_LOCKER','AVG_PREP_VID_TIME',\n",
    "                   'LARGEST_ORDER_SIZE','MASTER_CLASSES_ATTENDED','MEDIAN_MEAL_RATING',\n",
    "                   'AVG_CLICKS_PER_VISIT','TOTAL_PHOTOS_VIEWED','junk','personal',\n",
    "                   'work','NUM_OF_NAMES','abv_TOTAL_MEALS_ORDERED','abv_UNIQUE_MEALS_PURCH',\n",
    "                   'AVG_PRICE_MEAL','med_rater'],\n",
    " \n",
    " # significant variables only (set 1)\n",
    " 'logit_sig'    : ['MOBILE_NUMBER','CANCELLATIONS_BEFORE_NOON',\n",
    "                   'TASTES_AND_PREFERENCES','NUM_OF_NAMES',\n",
    "                   'PC_LOGINS','EARLY_DELIVERIES',\n",
    "                   'work','personal','REFRIGERATED_LOCKER',\n",
    "                   'abv_TOTAL_MEALS_ORDERED'],\n",
    "\n",
    " # significant variables only (set 2)\n",
    " 'logit_sig_2'  : ['MOBILE_NUMBER', 'CANCELLATIONS_BEFORE_NOON', \n",
    "                  'TASTES_AND_PREFERENCES', 'PC_LOGINS', 'EARLY_DELIVERIES',\n",
    "                  'REFRIGERATED_LOCKER', 'junk', 'work', \n",
    "                  'NUM_OF_NAMES'],\n",
    " \n",
    " # significant variables only (set 3)\n",
    " 'logit_sig_3'  : ['REVENUE','CONTACTS_W_CUSTOMER_SERVICE','MOBILE_NUMBER',\n",
    "                   'CANCELLATIONS_BEFORE_NOON','TASTES_AND_PREFERENCES',\n",
    "                   'PC_LOGINS','EARLY_DELIVERIES','REFRIGERATED_LOCKER',\n",
    "                   'MASTER_CLASSES_ATTENDED','junk','work','NUM_OF_NAMES',\n",
    "                   'abv_TOTAL_MEALS_ORDERED','med_rater' ]\n",
    "\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#declaring variables for the log reg model\n",
    "chef_data   =  chef.loc[ : , variable_dict['logit_full']]\n",
    "chef_target =  chef.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "# train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                chef_data,\n",
    "                                chef_target,\n",
    "                                random_state = 219,\n",
    "                                test_size    = 0.25,\n",
    "                                stratify     = chef_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Tuned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# PARAMETER TUNING for LOG REGRESSION #\n",
    "########################################\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "C_space          = pd.np.arange(0.1, 5.0, 0.1)\n",
    "warm_start_space = [True, False]\n",
    "solver_space     = ['newton-cg', 'sag', 'lbfgs']\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'C'          : C_space,\n",
    "              'warm_start' : warm_start_space,\n",
    "              'solver'     : solver_space}\n",
    "\n",
    "\n",
    "#the model object without hyperparameters\n",
    "lr_tuned = LogisticRegression(random_state = 219,\n",
    "                              max_iter     = 1000)\n",
    "\n",
    "# GridSearchCV object paramters\n",
    "lr_tuned_cv = RandomizedSearchCV(estimator           = lr_tuned,  \n",
    "                                 param_distributions = param_grid, \n",
    "                                 cv                  = 3,         \n",
    "                                 n_iter              = 1000,        \n",
    "                                 random_state        = 219,       \n",
    "                                 scoring = make_scorer(\n",
    "                                           roc_auc_score,\n",
    "                                           needs_threshold = False)) # scoring criteria (AUC)\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "lr_tuned_cv.fit(chef_data, chef_target)\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", lr_tuned_cv.best_params_)\n",
    "print(\"Tuned CV AUC      :\", lr_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Tuned Training ACCURACY: 0.7464\n",
      "LR Tuned Testing  ACCURACY: 0.7515\n",
      "LR Tuned AUC Score        : 0.6596\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a logistic regression model with tuned parameters\n",
    "#parameters come from above when tuning the model below\n",
    "\n",
    "lr_tuned = LogisticRegression(C            = 3.2,\n",
    "                              random_state = 219, \n",
    "                              solver       = 'newton-cg', \n",
    "                              warm_start   = True)\n",
    "\n",
    "#fitting the data\n",
    "lr_tuned_fit = lr_tuned.fit(x_train, y_train)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "lr_tuned_pred = lr_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('LR Tuned Training ACCURACY:', lr_tuned.score(x_train, y_train).round(4))\n",
    "print('LR Tuned Testing  ACCURACY:', lr_tuned.score(x_test, y_test).round(4))\n",
    "print('LR Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = lr_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lr_tuned_train_score = lr_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "lr_tuned_test_score  = lr_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "lr_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = lr_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "lrtuned_tn, \\\n",
    "lrtuned_fp, \\\n",
    "lrtuned_fn, \\\n",
    "lrtuned_tp = confusion_matrix(y_true = y_test, y_pred = lr_tuned_pred).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Initiating the data to be used on the full tree\n",
    "chef_data   =  chef.loc[ : , variable_dict['logit_full']]\n",
    "chef_target =  chef.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "# train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                chef_data,\n",
    "                                chef_target,\n",
    "                                random_state = 219,\n",
    "                                test_size    = 0.25,\n",
    "                                stratify     = chef_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Tree Training ACCURACY: 1.0\n",
      "Full Tree Testing ACCURACY : 0.6509\n",
      "Full Tree AUC Score: 0.6127\n"
     ]
    }
   ],
   "source": [
    "# Initiating a Full Tree Model\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "full_tree_fit = full_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "full_tree_pred = full_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Full Tree Training ACCURACY:', full_tree_fit.score(x_train,\n",
    "                                                    y_train).round(4))\n",
    "\n",
    "print('Full Tree Testing ACCURACY :', full_tree_fit.score(x_test,\n",
    "                                                    y_test).round(4))\n",
    "\n",
    "print('Full Tree AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                                            y_score = full_tree_pred).round(4))\n",
    "\n",
    "# save scores\n",
    "full_tree_train_score = full_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "full_tree_test_score  = full_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "# saving AUC\n",
    "full_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = full_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "full_tree_tn, \\\n",
    "full_tree_fp, \\\n",
    "full_tree_fn, \\\n",
    "full_tree_tp = confusion_matrix(y_true = y_test, y_pred = full_tree_pred).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruned Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Initiating data in the pruned tree model\n",
    "chef_data   =  chef.loc[ : , variable_dict['logit_full']]\n",
    "chef_target =  chef.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "# train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                    chef_data,\n",
    "                    chef_target,\n",
    "                    random_state = 219,\n",
    "                    test_size    = 0.25,\n",
    "                    stratify     = chef_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7402\n",
      "Testing  ACCURACY: 0.7762\n",
      "AUC Score        : 0.732\n"
     ]
    }
   ],
   "source": [
    "# Initiating a Pruned Tree Model\n",
    "pruned_tree = DecisionTreeClassifier(max_depth        = 3,\n",
    "                                     min_samples_leaf = 25,\n",
    "                                     random_state     = 219)\n",
    "\n",
    "# FITTING the training data\n",
    "pruned_tree_fit  = pruned_tree.fit(chef_data, chef_target)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "pruned_tree_pred = pruned_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', pruned_tree_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', pruned_tree_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = pruned_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = pruned_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = pruned_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = pruned_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#creating variables from confusion matrix\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = pruned_tree_pred).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuned Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Initiating data in the tuned classification tree model\n",
    "chef_data   =  chef.loc[ : , variable_dict['logit_sig_2']]\n",
    "chef_target =  chef.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "# train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                chef_data,\n",
    "                                chef_target,\n",
    "                                random_state = 219,\n",
    "                                test_size    = 0.25,\n",
    "                                stratify     = chef_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-4a735b0e6a36>:6: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  depth_space     = pd.np.arange(1, 25, 1)\n",
      "<ipython-input-55-4a735b0e6a36>:7: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  leaf_space      = pd.np.arange(1, 100, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameters  : {'splitter': 'best', 'min_samples_leaf': 16, 'max_depth': 3, 'criterion': 'gini'}\n",
      "Tuned Training AUC: 0.7032\n"
     ]
    }
   ],
   "source": [
    "##        Tree Parameter Tuning      ##\n",
    "#######################################\n",
    "criterion_space = ['gini', 'entropy']\n",
    "splitter_space  = ['best', 'random']\n",
    "depth_space     = pd.np.arange(1, 25, 1)\n",
    "leaf_space      = pd.np.arange(1, 100, 1)\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'criterion'        : criterion_space,\n",
    "              'splitter'         : splitter_space,\n",
    "              'max_depth'        : depth_space,\n",
    "              'min_samples_leaf' : leaf_space}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "tuned_tree = DecisionTreeClassifier(random_state = 219)\n",
    "# RandomizedSearchCV object\n",
    "tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "                                   param_distributions   = param_grid,\n",
    "                                   cv                    = 3,\n",
    "                                   n_iter                = 1000, # changed for the sake of time\n",
    "                                   random_state          = 219,\n",
    "                                   scoring = make_scorer(roc_auc_score,\n",
    "                                             needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "tuned_tree_cv.fit(chef_data, chef_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Tree Training ACCURACY: 0.7402\n",
      "Tuned Tree Testing ACCURACY : 0.7762\n",
      "Tuned Tree AUC Score        : 0.732\n"
     ]
    }
   ],
   "source": [
    "# building classification model based on hyperparameter tuning results\n",
    "#tuning results came from above where the hyperparameter tuning code was used\n",
    "\n",
    "# classification tree model with tuned values from above\n",
    "tree_tuned = DecisionTreeClassifier(criterion        = 'gini',\n",
    "                                    max_depth        = 3,\n",
    "                                    max_features     = None,\n",
    "                                    min_samples_leaf = 16,\n",
    "                                    random_state     = 219,\n",
    "                                    splitter         = 'best')\n",
    "\n",
    "# Fitting training data\n",
    "tree_tuned_fit  = tree_tuned.fit(chef_data, chef_target)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "tree_tuned_pred = tree_tuned.predict(x_test)\n",
    "\n",
    "# SCORING the results\n",
    "print('Tuned Tree Training ACCURACY:', tree_tuned.score(x_train, y_train).round(4))\n",
    "print('Tuned Tree Testing ACCURACY :', tree_tuned.score(x_test, y_test).round(4))\n",
    "print('Tuned Tree AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                                     y_score = tree_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "tree_tuned_train_score = tree_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "tree_tuned_test_score  = tree_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "tree_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = tree_tuned_pred).round(4) # auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_tree_tn, \\\n",
    "tuned_tree_fp, \\\n",
    "tuned_tree_fn, \\\n",
    "tuned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_tuned_pred).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#declaring the correct variables to be used in random forest\n",
    "chef_data   =  chef.loc[ : , variable_dict['logit_sig_2']]\n",
    "chef_target =  chef.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "# train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                chef_data,\n",
    "                                chef_target,\n",
    "                                random_state = 219,\n",
    "                                test_size    = 0.25,\n",
    "                                stratify     = chef_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-6d6f2cfa3e93>:18: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  estimator_space  = pd.np.arange(100, 1100, 250)\n",
      "<ipython-input-37-6d6f2cfa3e93>:19: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  leaf_space       = pd.np.arange(1, 31, 10)\n",
      "C:\\Users\\Nguye\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:278: UserWarning: The total space of parameters 96 is smaller than n_iter=500. Running 96 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameters  : {'warm_start': True, 'n_estimators': 600, 'min_samples_leaf': 21, 'criterion': 'gini', 'bootstrap': False}\n",
      "Tuned Training AUC: 0.6815\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 100,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = None,\n",
    "                                    min_samples_leaf = 2,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = 219)\n",
    "# Fit the training data\n",
    "rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting on testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# declaring hyperparameter space\n",
    "estimator_space  = pd.np.arange(100, 1100, 250)\n",
    "leaf_space       = pd.np.arange(1, 31, 10)\n",
    "criterion_space  = ['gini', 'entropy']\n",
    "bootstrap_space  = [True, False]\n",
    "warm_start_space = [True, False]\n",
    "\n",
    "\n",
    "# create hyperparameter grid\n",
    "param_grid = {'n_estimators'     : estimator_space,\n",
    "              'min_samples_leaf' : leaf_space,\n",
    "              'criterion'        : criterion_space,\n",
    "              'bootstrap'        : bootstrap_space,\n",
    "              'warm_start'       : warm_start_space}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "forest_grid = RandomForestClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "forest_cv = RandomizedSearchCV(estimator           = forest_grid,\n",
    "                               param_distributions = param_grid,\n",
    "                               cv                  = 3,\n",
    "                               n_iter              = 500,\n",
    "                               scoring             = make_scorer(roc_auc_score,\n",
    "                               needs_threshold     = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "forest_cv.fit(chef_data, chef_target)\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", forest_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", forest_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Tuned Training ACCURACY: 0.7656\n",
      "Forest Tuned Testing  ACCURACY: 0.7885\n",
      "Forest Tuned AUC Score        : 0.719\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# copying over the tune parameters into the model \n",
    "# avoids running another RandomizedSearchCV\n",
    "forest_tuned = RandomForestClassifier(n_estimators     = 600,\n",
    "                                      criterion        = 'gini',\n",
    "                                      max_depth        = None,\n",
    "                                      min_samples_leaf = 21,\n",
    "                                      bootstrap        = False,\n",
    "                                      warm_start       = True,\n",
    "                                      random_state     = 219)\n",
    "\n",
    "# Fit model object\n",
    "forest_tuned_fit = forest_tuned.fit(chef_data, chef_target)\n",
    "\n",
    "# Predicting based on the testing set\n",
    "forest_tuned_pred = forest_tuned_fit.predict(x_test)\n",
    "\n",
    "# Score the results\n",
    "print('Forest Tuned Training ACCURACY:', forest_tuned.score(x_train, y_train).round(4))\n",
    "print('Forest Tuned Testing  ACCURACY:', forest_tuned.score(x_test, y_test).round(4))\n",
    "print('Forest Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                                       y_score = forest_tuned_pred).round(4))\n",
    "\n",
    "# saving score data for future use\n",
    "forest_tuned_train_score = forest_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "forest_tuned_test_score  = forest_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "# saving the AUC score\n",
    "forest_tuned_auc = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = forest_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Initiating confusing matrix values\n",
    "tuned_rf_tn, \\\n",
    "tuned_rf_fp, \\\n",
    "tuned_rf_fn, \\\n",
    "tuned_rf_tp = confusion_matrix(y_true = y_test, y_pred = forest_tuned_pred).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#initiating dataset to use in classification\n",
    "chef_data   =  chef.loc[ : , variable_dict['logit_sig_2']]\n",
    "chef_target =  chef.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "# train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                chef_data,\n",
    "                                chef_target,\n",
    "                                random_state = 219,\n",
    "                                test_size    = 0.25,\n",
    "                                stratify     = chef_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is: 17\n"
     ]
    }
   ],
   "source": [
    "# determining the optimal number of neighbors\n",
    "opt_neighbors = optimal_neighbors(x_data        = chef_data,\n",
    "                                  y_data        = chef_target,\n",
    "                                  response_type = 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Training ACCURACY: 0.7546\n",
      "KNN Testing  ACCURACY: 0.7392\n",
      "KNN AUC Score        : 0.6455\n"
     ]
    }
   ],
   "source": [
    "#Scaling the data through the code below\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(chef_data)\n",
    "\n",
    "x_scaled     = scaler.transform(chef_data)\n",
    "\n",
    "# converting scaled data to a DF\n",
    "x_scaled_df  = pd.DataFrame(x_scaled) \n",
    "\n",
    "\n",
    "# train-test split with newly scaled data\n",
    "x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "            x_scaled_df,\n",
    "            chef_target,\n",
    "            random_state = 219,\n",
    "            test_size = 0.25,\n",
    "            stratify = chef_target)\n",
    "\n",
    "# KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = opt_neighbors)\n",
    "\n",
    "knn_fit = knn_opt.fit(x_train_scaled, y_train_scaled)\n",
    "\n",
    "knn_pred = knn_fit.predict(x_test_scaled)\n",
    "\n",
    "# Print Scores\n",
    "print('KNN Training ACCURACY:', knn_fit.score(x_train_scaled, y_train_scaled).round(4))\n",
    "print('KNN Testing  ACCURACY:', knn_fit.score(x_test_scaled, y_test_scaled).round(4))\n",
    "print('KNN AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                              y_score = knn_pred).round(4))\n",
    "\n",
    "# saving scores\n",
    "knn_train_score = knn_fit.score(x_train_scaled, y_train_scaled).round(4)\n",
    "knn_test_score  = knn_fit.score(x_test_scaled, y_test_scaled).round(4)\n",
    "\n",
    "# saving AUC score\n",
    "knn_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "knn_tree_tn, \\\n",
    "knn_tree_fp, \\\n",
    "knn_tree_fn, \\\n",
    "knn_tree_tp = confusion_matrix(y_true = y_test, y_pred = knn_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "\n",
    "#Model Names \n",
    "    'Model Name'    : ['Logistic Tuned', 'Full Tree', 'Pruned Tree', 'Scaled KNN',\n",
    "                      'Tuned Tree', 'Tuned Forest'],\n",
    "#AUC Score values           \n",
    "    'AUC Score' : [lr_tuned_auc , full_tree_auc_score, pruned_tree_auc_score, \n",
    "                   knn_auc_score, tree_tuned_auc, forest_tuned_auc],\n",
    "    \n",
    "#training accuracy values   \n",
    "    'Training Accuracy' : [lr_tuned_train_score, full_tree_train_score,\n",
    "                           pruned_tree_train_score, knn_train_score,\n",
    "                          tree_tuned_train_score, forest_tuned_train_score],\n",
    "#testing accuracy values \n",
    "    'Testing Accuracy'  : [lr_tuned_test_score, full_tree_test_score,\n",
    "                           pruned_tree_test_score, knn_test_score,\n",
    "                          tree_tuned_test_score, forest_tuned_test_score],\n",
    "#confusion matrix values\n",
    "    'Confusion Matrix'  : [(lrtuned_tn, lrtuned_fp, lrtuned_fn, lrtuned_tp),\n",
    "                           (full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp),\n",
    "                           (pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp),\n",
    "                           (knn_tree_tn, knn_tree_fp, knn_tree_fn, knn_tree_tp),\n",
    "                           (tuned_tree_tn, tuned_tree_fp, tuned_tree_fn, tuned_tree_tp),\n",
    "                           (tuned_rf_tn,tuned_rf_fp,tuned_rf_fn,tuned_rf_tp)]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)\n",
    "\n",
    "\n",
    "# sending model results to Excel\n",
    "model_performance.to_excel('./chef_modelperformance_Vi.xlsx',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Therefore, my best model based on the AUC score is the Pruned Tree Model.\t\n",
      "Seen from the values below.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.7402</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>(95, 61, 48, 283)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.7402</td>\n",
       "      <td>0.7762</td>\n",
       "      <td>(95, 61, 48, 283)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tuned Forest</td>\n",
       "      <td>0.7190</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.7885</td>\n",
       "      <td>(82, 74, 29, 302)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Tuned</td>\n",
       "      <td>0.6596</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.7515</td>\n",
       "      <td>(63, 93, 28, 303)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scaled KNN</td>\n",
       "      <td>0.6455</td>\n",
       "      <td>0.7546</td>\n",
       "      <td>0.7392</td>\n",
       "      <td>(60, 96, 31, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6127</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6509</td>\n",
       "      <td>(79, 77, 93, 238)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "2     Pruned Tree     0.7320             0.7402            0.7762  (95, 61, 48, 283)\n",
       "4      Tuned Tree     0.7320             0.7402            0.7762  (95, 61, 48, 283)\n",
       "5    Tuned Forest     0.7190             0.7656            0.7885  (82, 74, 29, 302)\n",
       "0  Logistic Tuned     0.6596             0.7464            0.7515  (63, 93, 28, 303)\n",
       "3      Scaled KNN     0.6455             0.7546            0.7392  (60, 96, 31, 300)\n",
       "1       Full Tree     0.6127             1.0000            0.6509  (79, 77, 93, 238)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printout for the model chosen\n",
    "\n",
    "print(\"\"\"Therefore, my best model based on the AUC score is the Pruned Tree Model.\\t\n",
    "Seen from the values below.\"\"\")\n",
    "\n",
    "\n",
    "model_performance.sort_values(by = 'AUC Score', ascending = False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
